# LLM局限性
* 知识时效性受限:如何让LLM能够获取最新的知识
* 专业能力有限:如何打造垂域大模型
* 定制化成本高:如何打造个人专属的LLM应用
# 模型改进
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/e096e2a4-a897-466c-9e97-b01892079a4b)
## RAG
* 检索增强生成技术（Retrieval-Augmented Generation），通过在语言模型生成答案之前，先从广泛的文档数据库中检索相关信息，然后利用这些信息来引导生成过程，极大地提升了内容的准确性和相关性。
* RAG 有效地缓解了幻觉问题，提高了知识更新的速度，并增强了内容生成的可追溯性，使得大型语言模型在实际应用中变得更加实用和可信。
* 主要包括包括三个基本步骤：
  * 索引 — 将文档库分割成较短的 Chunk，并通过编码器构建向量索引。
  * 检索 — 根据问题和 chunks 的相似度检索相关文档片段。
  * 生成 — 以检索到的上下文为条件，生成问题的回答。
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/7ffda48f-6e8c-46a9-b64e-702a500f02fa)
# 基于lang chain搭建RAG应用
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/86e4f028-9885-4e6b-a087-83e2e79e7ac4)
## 构建向量数据库
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/5ecdfa6d-9b44-4b72-b495-6e66519fb016)
## 搭建知识库助手
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/8325f7be-c87f-4703-94d7-6dfa8104896c)
## 构造检索问答链
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/0e6aa72c-72be-4dd8-b329-311a35ab2b55)
# RAG方案优化建议
![image](https://github.com/baijiesong/InternLM_Learning/assets/105435837/33777b8f-a278-4857-8e9c-8853aa7ea25f)

### 参考视频：https://link.csdn.net/?target=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1sT4y1p71V%2F%3Fvd_source%3Dd47b98d4c706bfb2cf96edf04d040885
### 参考教程：https://github.com/InternLM/tutorial
